{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#필요 library import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Activation\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['2002-11-29', 18, 2, ..., -2.4852e-07, 14.1, 1019.0],\n       ['2002-11-29', 19, 2, ..., -2.35876e-06, 14.1, 1018.51],\n       ['2002-11-29', 20, 2, ..., -1.10679e-05, 14.1, 1018.02],\n       ...,\n       ['2003-06-05', 4, 2, ..., -2.523660074, 17.44, 1006.7142857142856],\n       ['2003-06-05', 5, 2, ..., -2.501656526, 17.4, 1006.8571428571428],\n       ['2003-06-05', 6, 2, ..., -2.48076972, 17.34, 1007.0]],\n      dtype=object)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data files\n",
    "file = '1996-2020_U3.csv'\n",
    "u1a = '2002-2004_U1a.csv'\n",
    "u1b = '2002-2004_U1b.csv'\n",
    "u2a = '2002-2004_U2a.csv'\n",
    "u2b = '2002-2004_U2b.csv'\n",
    "u3a = '2002-2004_U3a.csv'\n",
    "u3b = '2002-2004_U3b.csv'\n",
    "u4a = '2002-2004_U4a.csv'\n",
    "u4b = '2002-2004_U4b.csv'\n",
    "u5a = '2002-2004_U5a.csv'\n",
    "obs_file = 'SST_merge.csv'\n",
    "\n",
    "df = pd.read_csv(file, encoding='cp949')\n",
    "df_u1a = pd.read_csv(u1a, encoding='cp949')\n",
    "df_u1b = pd.read_csv(u1b, encoding='cp949')\n",
    "df_u2a = pd.read_csv(u2a, encoding='cp949')\n",
    "df_u2b = pd.read_csv(u2b, encoding='cp949')\n",
    "df_u3a = pd.read_csv(u3a, encoding='cp949')\n",
    "df_u3b = pd.read_csv(u3b, encoding='cp949') #결측값이 많아 test용으로 사용\n",
    "df_u4a = pd.read_csv(u4a, encoding='cp949')\n",
    "df_u4b = pd.read_csv(u4b, encoding='cp949')\n",
    "df_u5a = pd.read_csv(u5a, encoding='cp949')\n",
    "obs = pd.read_csv(obs_file, encoding='cp949') #해양수산부 바다누리 해양정보서비스에서 제공하는 수온, 기압 데이터\n",
    "\n",
    "\n",
    "file_list = [df_u1a, df_u1b, df_u2a, df_u2b, df_u3a, df_u3b, df_u4a, df_u4b, df_u5a]\n",
    "str_list = ['df_u1a', 'df_u1b', 'df_u2a', 'df_u2b', 'df_u3a', 'df_u3b', 'df_u4a', 'df_u4b', 'df_u5a']\n",
    "\n",
    "#날짜 형식으로 변환 후 지점별 번호 부여\n",
    "for i, j in zip(file_list, str_list):\n",
    "    date = i['Year'].astype(str) + i['Month'].astype(str) + i['Day'].astype(str)\n",
    "    i.insert(0, 'Date', date)\n",
    "    i['Date'] = pd.to_datetime(i['Date'],format='%Y%m%d', errors='raise')\n",
    "\n",
    "    if j == 'df_u1a' or j == 'df_u1b':\n",
    "        i.insert(5, 'Station', 0)\n",
    "    elif j == 'df_u2a' or j == 'df_u2b':\n",
    "        i.insert(5, 'Station', 1)\n",
    "    elif j == 'df_u3a' or 'df_u3b':\n",
    "        i.insert(5, 'Station', 2)\n",
    "    elif j =='df_u4a' or j == 'df_u4b':\n",
    "        i.insert(5, 'Station', 3)\n",
    "    else:\n",
    "        i.insert(5, 'Station', 4)\n",
    "\n",
    "\n",
    "drop_col = ['Year', 'Month', 'Day', 'Minute', 'Second']\n",
    "for j in file_list:\n",
    "    j.drop(drop_col, axis=1, inplace=True)\n",
    "\n",
    "for k, l in zip(file_list, str_list):\n",
    "    k.rename(columns = {'Ur Current speed (cm/s)' : l + '_current_speed_(cm/s)', 'Depth (meter)' : l + '_Depth_(m)'}, inplace=True)\n",
    "\n",
    "obs['Date'] = obs['Date'].astype('str')\n",
    "\n",
    "def merge_files(file1, file2):\n",
    "    file1['Date'] = file1['Date'].astype('str')\n",
    "    file1 = pd.merge(file1, file2, on=['Date', 'Hour'])\n",
    "    file1 = np.array(file1)\n",
    "\n",
    "    return file1\n",
    "\n",
    "#코드 예쁘게? ##########################@@@@@@@@@@@@@@@@ 루프로 하면 안 됨 덮어씌우기 때문인듯?\n",
    "df_u1a = merge_files(df_u1a, obs)\n",
    "df_u1b = merge_files(df_u1b, obs)\n",
    "df_u2a = merge_files(df_u2a, obs)\n",
    "df_u2b = merge_files(df_u2b, obs)\n",
    "df_u3a = merge_files(df_u3a, obs)\n",
    "df_u3b = merge_files(df_u3b, obs)\n",
    "df_u4a = merge_files(df_u4a, obs)\n",
    "df_u4b = merge_files(df_u4b, obs)\n",
    "df_u5a = merge_files(df_u5a, obs)\n",
    "\n",
    "df_u3b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  1.        ,  18.        ,   2.        , ...,   0.30672544,\n          0.37567406,   0.70268034],\n       [  1.        ,  19.        ,   2.        , ...,   0.30672539,\n          0.37567406,   0.69457313],\n       [  1.        ,  20.        ,   2.        , ...,   0.30672517,\n          0.37567406,   0.68646592],\n       ...,\n       [168.        ,   4.        ,   2.        , ...,   0.24279786,\n          0.57579389,   0.4994091 ],\n       [168.        ,   5.        ,   2.        , ...,   0.24335524,\n          0.57339724,   0.50177271],\n       [168.        ,   6.        ,   2.        , ...,   0.24388433,\n          0.56980228,   0.50413633]])"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoding 두 번 하는 방식 말고 바꿀 수 있으면 바꾸기 아니면 말고\n",
    "file_list = [df_u1a, df_u1b, df_u2a, df_u2b, df_u3a, df_u3b, df_u4a, df_u4b, df_u5a]\n",
    "df_all = np.concatenate(file_list)\n",
    "\n",
    "#labelencoding\n",
    "le = LabelEncoder()\n",
    "df_all[:, 0] = le.fit_transform(df_all[:, 0])\n",
    "\n",
    "#minmax scaling\n",
    "df_all[:, 4] = minmax_scale(df_all[:,4])\n",
    "df_all[:, -2] = minmax_scale(df_all[:, -2])\n",
    "df_all[:, -1] = minmax_scale(df_all[:, -1])\n",
    "\n",
    "df_u3b = df_all[(df_all[:, 2] == 2) & (df_all[:, 3] == 2240)]\n",
    "df_u3b = df_u3b.astype(float)\n",
    "\n",
    "df_u3b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.00000000e+00, 1.10000000e+01, 0.00000000e+00, ...,\n        3.06725486e-01, 3.69682445e-01, 7.03011251e-01],\n       [2.00000000e+00, 1.20000000e+01, 0.00000000e+00, ...,\n        3.06725820e-01, 3.69682445e-01, 6.92753144e-01],\n       [2.00000000e+00, 1.30000000e+01, 0.00000000e+00, ...,\n        3.06727199e-01, 3.69682445e-01, 6.86135010e-01],\n       ...,\n       [4.33000000e+02, 6.00000000e+00, 2.00000000e+00, ...,\n        6.41518331e-01, 1.77950869e-01, 6.19953673e-01],\n       [4.33000000e+02, 7.00000000e+00, 2.00000000e+00, ...,\n        6.42127778e-01, 1.77950869e-01, 6.19953673e-01],\n       [4.33000000e+02, 8.00000000e+00, 2.00000000e+00, ...,\n        6.42956242e-01, 1.77950869e-01, 6.17140966e-01]])"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [df_u1a, df_u1b, df_u2a, df_u2b, df_u3a, df_u4a, df_u4b, df_u5a] #df_u3b 제외\n",
    "df_all = np.concatenate(file_list)\n",
    "le = LabelEncoder()\n",
    "df_all[:, 0] = le.fit_transform(df_all[:, 0])\n",
    "df_all[:, 4] = minmax_scale(df_all[:, 4])\n",
    "df_all[:, -2] = minmax_scale(df_all[:, -2])\n",
    "df_all[:, -1] = minmax_scale(df_all[:, -1])\n",
    "\n",
    "df_all = df_all.astype(float)\n",
    "df_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "           0     1    2       3         5         6\n0        2.0  11.0  0.0  1760.0  0.369682  0.703011\n1        2.0  12.0  0.0  1760.0  0.369682  0.692753\n2        2.0  13.0  0.0  1760.0  0.369682  0.686135\n3        2.0  14.0  0.0  1760.0  0.369682  0.686135\n4        2.0  15.0  0.0  1760.0  0.369682  0.686135\n...      ...   ...  ...     ...       ...       ...\n84551  433.0   4.0  2.0  2060.0  0.178550  0.607048\n84552  433.0   5.0  2.0  2060.0  0.177951  0.619954\n84553  433.0   6.0  2.0  2060.0  0.177951  0.619954\n84554  433.0   7.0  2.0  2060.0  0.177951  0.619954\n84555  433.0   8.0  2.0  2060.0  0.177951  0.617141\n\n[84556 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>1760.0</td>\n      <td>0.369682</td>\n      <td>0.703011</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>1760.0</td>\n      <td>0.369682</td>\n      <td>0.692753</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>1760.0</td>\n      <td>0.369682</td>\n      <td>0.686135</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>1760.0</td>\n      <td>0.369682</td>\n      <td>0.686135</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>1760.0</td>\n      <td>0.369682</td>\n      <td>0.686135</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>84551</th>\n      <td>433.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>2060.0</td>\n      <td>0.178550</td>\n      <td>0.607048</td>\n    </tr>\n    <tr>\n      <th>84552</th>\n      <td>433.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2060.0</td>\n      <td>0.177951</td>\n      <td>0.619954</td>\n    </tr>\n    <tr>\n      <th>84553</th>\n      <td>433.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>2060.0</td>\n      <td>0.177951</td>\n      <td>0.619954</td>\n    </tr>\n    <tr>\n      <th>84554</th>\n      <td>433.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>2060.0</td>\n      <td>0.177951</td>\n      <td>0.619954</td>\n    </tr>\n    <tr>\n      <th>84555</th>\n      <td>433.0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>2060.0</td>\n      <td>0.177951</td>\n      <td>0.617141</td>\n    </tr>\n  </tbody>\n</table>\n<p>84556 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train, test set\n",
    "x_tr = pd.DataFrame(df_all).iloc[:, [0,1,2,3,5,6]]\n",
    "y_tr = pd.DataFrame(df_all[:, 4]) # 유속\n",
    "\n",
    "x_test = pd.DataFrame(df_u3b).iloc[:, [0,1,2,3,5,6]]\n",
    "y_test = pd.DataFrame(df_u3b[:, 4]) #정답값\n",
    "x_tr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expect the data to StructuredDataInput to have shape (batch_size, num_features), but got input shape [32, 6, 1].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [111]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#AutoKeras\u001B[39;00m\n\u001B[0;32m      2\u001B[0m model_2 \u001B[38;5;241m=\u001B[39m ak\u001B[38;5;241m.\u001B[39mStructuredDataRegressor(max_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, overwrite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mmodel_2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_tr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m pred2 \u001B[38;5;241m=\u001B[39m model_2\u001B[38;5;241m.\u001B[39mpredict(x_test)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\autokeras\\tasks\\structured_data.py:139\u001B[0m, in \u001B[0;36mBaseStructuredDataPipeline.fit\u001B[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001B[0m\n\u001B[0;32m    135\u001B[0m         validation_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_from_csv(x_val, y_val)\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_in_fit(x)\n\u001B[1;32m--> 139\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\autokeras\\auto_model.py:283\u001B[0m, in \u001B[0;36mAutoModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    278\u001B[0m     validation_split \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    280\u001B[0m dataset, validation_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_to_dataset(\n\u001B[0;32m    281\u001B[0m     x\u001B[38;5;241m=\u001B[39mx, y\u001B[38;5;241m=\u001B[39my, validation_data\u001B[38;5;241m=\u001B[39mvalidation_data, batch_size\u001B[38;5;241m=\u001B[39mbatch_size\n\u001B[0;32m    282\u001B[0m )\n\u001B[1;32m--> 283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_analyze_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_hyper_pipeline(dataset)\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# Split the data with validation_split.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\autokeras\\auto_model.py:376\u001B[0m, in \u001B[0;36mAutoModel._analyze_data\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    373\u001B[0m         analyser\u001B[38;5;241m.\u001B[39mupdate(item)\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m analyser \u001B[38;5;129;01min\u001B[39;00m analysers:\n\u001B[1;32m--> 376\u001B[0m     \u001B[43manalyser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hm, analyser \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_heads, analysers):\n\u001B[0;32m    379\u001B[0m     hm\u001B[38;5;241m.\u001B[39mconfig_from_analyser(analyser)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\autokeras\\analysers\\input_analysers.py:103\u001B[0m, in \u001B[0;36mStructuredDataAnalyser.finalize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfinalize\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 103\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer_column_types()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\autokeras\\analysers\\input_analysers.py:111\u001B[0m, in \u001B[0;36mStructuredDataAnalyser.check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m--> 111\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    112\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpect the data to \u001B[39m\u001B[38;5;132;01m{input_name}\u001B[39;00m\u001B[38;5;124m to have shape \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    113\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(batch_size, num_features), but \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    114\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgot input shape \u001B[39m\u001B[38;5;132;01m{shape}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    115\u001B[0m                 input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_input_name(), shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    116\u001B[0m             )\n\u001B[0;32m    117\u001B[0m         )\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;66;03m# Fill in the column_names\u001B[39;00m\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumn_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: Expect the data to StructuredDataInput to have shape (batch_size, num_features), but got input shape [32, 6, 1]."
     ]
    }
   ],
   "source": [
    "#AutoKeras\n",
    "model_2 = ak.StructuredDataRegressor(max_trials=10, seed=42, overwrite=True)\n",
    "model_2.fit(x_tr, y_tr, verbose=1, epochs=50)\n",
    "pred2 = model_2.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#AutoKeras 결과 확인\n",
    "plt.plot(pred2, color='yellow')\n",
    "# plt.xlim(75000, 175000)\n",
    "plt.plot(y_test, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pred2)\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "pred2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#LSTM 학습을 위해 차원 추가\n",
    "x_tr = np.expand_dims(x_tr, -1)\n",
    "y_tr = np.expand_dims(y_tr, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#LSTM\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(50, return_sequences=True))\n",
    "model.add(CuDNNLSTM(1, return_sequences=False))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(optimizer='adam', loss='MSE', metrics=['accuracy'])\n",
    "model.fit(x_tr, y_tr, epochs=100, batch_size=128, shuffle=False)\n",
    "pred = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#LSTM 결과 확인\n",
    "plt.plot(pred, color='yellow')\n",
    "# plt.xlim(75000, 175000)\n",
    "plt.plot(y_test, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(y_test)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pred)\n",
    "plt.ylim([0, 0.5])\n",
    "plt.show()\n",
    "\n",
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}